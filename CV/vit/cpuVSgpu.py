import os

# ã€å…³é”®ã€‘æŒ‡å®šæ˜¾å¡ ID ä¸º 2
os.environ["CUDA_VISIBLE_DEVICES"] = "2"

import torch
from transformers import ViTModel, ViTConfig
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
from typing import List, Union
import logging
import time
import torch.nn.functional as F

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


# ==========================================
# ä½ çš„åŸå§‹ç±»å®šä¹‰ (ä¿æŒä¸å˜)
# ==========================================
class MyViTFeatureExtractor:
    def __init__(self, local_model_path: str) -> None:
        if not os.path.isdir(local_model_path):
            raise NotADirectoryError(f"Model path not found: {local_model_path}")

        logging.info(f"Loading model from: {local_model_path}")

        # self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.device = torch.device("cpu")

        logging.info(f"Using device: {self.device}")

        try:
            self.config = ViTConfig.from_pretrained(local_model_path, local_files_only=True)
            self.model = ViTModel.from_pretrained(local_model_path, config=self.config, local_files_only=True)
        except Exception as e:
            logging.error(f"Failed to load model: {e}")
            raise

        self.model.to(self.device)
        self.model.eval()

        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ])

        self.feature_dim = self.model.config.hidden_size

    def run(self, imgs: List[Union[str, np.ndarray, Image.Image]], normalize: bool = True) -> np.ndarray:
        # (åŸæœ‰çš„ run æ–¹æ³•ä¿ç•™ï¼Œä½†åœ¨æœ¬æ¬¡å‹åŠ›æµ‹è¯•ä¸­æˆ‘ä»¬ç›´æ¥è°ƒç”¨ model ä»¥è·³è¿‡ CPU IO ç“¶é¢ˆ)
        pass

    # ==========================================


# å‹åŠ›æµ‹è¯•é€»è¾‘
# ==========================================
def benchmark_throughput(model_path):
    print(f"\n{'=' * 60}")
    print(f"ğŸš€ å¼€å§‹ ViT-Base æ˜¾å­˜ä¸é€Ÿåº¦åŸºå‡†æµ‹è¯•")
    print(f"ğŸ“ ç›®æ ‡æ˜¾å¡: CUDA_VISIBLE_DEVICES={os.environ.get('CUDA_VISIBLE_DEVICES')}")
    print(f"{'=' * 60}\n")

    # 1. åˆå§‹åŒ–æ¨¡å‹
    try:
        extractor = MyViTFeatureExtractor(model_path)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    model = extractor.model
    device = extractor.device

    # 2. å®šä¹‰æµ‹è¯•èŒƒå›´: 1, 100, 200, ..., 1200
    batch_sizes = [1] + list(range(10, 201, 20))

    print(f"{'Batch Size':<12} | {'è€—æ—¶ (ms)':<12} | {'ååé‡ (img/s)':<18} | {'æ˜¾å­˜å ç”¨ (GB)':<15} | {'çŠ¶æ€':<10}")
    print("-" * 80)

    for batch_size in batch_sizes:
        try:
            # --- A. å‡†å¤‡æ•°æ® (æ¨¡æ‹Ÿ Tensorï¼Œä¸è®¡å…¥æ¨ç†æ—¶é—´) ---
            # å½¢çŠ¶: [Batch, 3, 224, 224]
            # æˆ‘ä»¬ä½¿ç”¨åŠç²¾åº¦(FP16)è¿˜æ˜¯å•ç²¾åº¦(FP32)å–å†³äºä½ çš„å®é™…åœºæ™¯ï¼Œè¿™é‡Œé»˜è®¤ç”¨ FP32 (Torché»˜è®¤)
            # å¦‚æœæƒ³æµ‹è¯• FP16ï¼Œå¯ä»¥å°† inputs è½¬ä¸º .half()
            inputs = torch.randn(batch_size, 3, 224, 224, device=device)

            # æ¸…ç†ä¹‹å‰çš„ç¼“å­˜ï¼Œç¡®ä¿æ˜¾å­˜è¯»æ•°å‡†ç¡®
            torch.cuda.empty_cache()
            torch.cuda.reset_peak_memory_stats()

            # --- B. é¢„çƒ­ (Warm up) ---
            # GPU é¦–æ¬¡è¿è¡Œä¼šæœ‰ overheadï¼Œå…ˆè·‘ä¸€æ¬¡ä¸è®¡æ—¶çš„
            with torch.no_grad():
                _ = model(inputs)

            torch.cuda.synchronize()  # ç­‰å¾…é¢„çƒ­å®Œæˆ

            # --- C. è®¡æ—¶æ¨ç† ---
            start_event = torch.cuda.Event(enable_timing=True)
            end_event = torch.cuda.Event(enable_timing=True)

            start_event.record()
            with torch.no_grad():
                # æ¨¡æ‹Ÿä½ çš„ run æ–¹æ³•ä¸­çš„æ ¸å¿ƒé€»è¾‘
                outputs = model(inputs)
                features = outputs.last_hidden_state[:, 0, :]
                # å¦‚æœåšäº† normalizeï¼Œé€šå¸¸å¼€é”€å¾ˆå°ï¼Œè¿™é‡Œä¸»è¦æµ‹æ¨¡å‹ forward
                features = F.normalize(features, p=2, dim=1)
            end_event.record()

            torch.cuda.synchronize()  # ç­‰å¾… GPU å®Œæˆæ‰€æœ‰è®¡ç®—

            # --- D. è®¡ç®—ç»Ÿè®¡ ---
            elapsed_time_ms = start_event.elapsed_time(end_event)  # æ¯«ç§’
            images_per_sec = batch_size / (elapsed_time_ms / 1000.0)

            # è·å–æ˜¾å­˜å³°å€¼
            max_memory = torch.cuda.max_memory_allocated() / (1024 ** 3)  # GB

            print(
                f"{batch_size:<12} | {elapsed_time_ms:<12.2f} | {images_per_sec:<18.2f} | {max_memory:<15.2f} | âœ… æˆåŠŸ")

            # ä¸»åŠ¨é‡Šæ”¾æ˜¾å­˜
            del inputs, outputs, features

        except RuntimeError as e:
            if 'out of memory' in str(e).lower():
                print(f"{batch_size:<12} | {'-':<12} | {'-':<18} | {'FAIL':<15} | âŒ æ˜¾å­˜æº¢å‡º (OOM)")
                torch.cuda.empty_cache()  # å°è¯•æ¢å¤
                break  # å·²ç»ç‚¸æ˜¾å­˜äº†ï¼Œåé¢æ›´å¤§çš„è‚¯å®šä¹Ÿä¸è¡Œï¼Œç›´æ¥åœæ­¢
            else:
                print(f"âŒ æœªçŸ¥é”™è¯¯ (Batch {batch_size}): {e}")
                break

    print("-" * 80)
    print("\nğŸ’¡ æç¤º:")
    print("1. 'ååé‡' è¶Šé«˜ï¼Œè¯´æ˜æ˜¾å¡åˆ©ç”¨ç‡è¶Šå¥½ã€‚")
    print("2. å®é™…å·¥ç¨‹ä¸­ï¼Œå»ºè®®é€‰æ‹©æœ€å¤§å¯ç”¨ Batch Size çš„ 70%-80%ï¼Œé˜²æ­¢æ˜¾å­˜ç¢ç‰‡åŒ–æˆ– YOLO è¿›ç¨‹æŠ¢å ã€‚")


if __name__ == "__main__":
    # è¯·ä¿®æ”¹ä¸ºä½ çš„å®é™…æ¨¡å‹è·¯å¾„
    MODEL_PATH = "/home/martin/ML/Model/pokemon_cls/vit-base-patch16-224-Pokemon03"

    benchmark_throughput(MODEL_PATH)