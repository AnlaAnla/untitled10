from sentence_transformers import SentenceTransformer
import numpy as np
import pandas as pd
import time


def batch_search_vec2text(texts, tag_list, vec_data, name_list, model, top_k=5):
    """
    æ‰¹é‡æœç´¢æ–‡æœ¬å¯¹åº”çš„å‘é‡ï¼Œå¹¶è¿”å›æœ€ç›¸ä¼¼çš„ top_k ä¸ªç»“æœã€‚

    Args:
        texts: å¾…æŸ¥è¯¢æ–‡æœ¬åˆ—è¡¨ã€‚
        vec_data: å‘é‡åº“æ•°æ®ã€‚
        name_list: å‘é‡åº“å¯¹åº”çš„åç§°åˆ—è¡¨ã€‚
        model: SentenceTransformer æ¨¡å‹ã€‚
        top_k: è¿”å›æœ€ç›¸ä¼¼ç»“æœçš„æ•°é‡ã€‚

    Returns:
        ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«æŸ¥è¯¢æ–‡æœ¬å’Œå¯¹åº”çš„ top_k ä¸ªç»“æœã€‚
    """

    # 1. æ‰¹é‡ç¼–ç æ–‡æœ¬
    output_vecs = model.encode(texts, normalize_embeddings=True, convert_to_numpy=True)

    # 2. æ‰¹é‡è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    #   output_vecs:  (num_queries, embedding_dim)
    #   vec_data:     (num_vectors_in_db, embedding_dim)
    #   similarities: (num_queries, num_vectors_in_db)
    similarities = np.dot(output_vecs, vec_data.T)  # åˆ©ç”¨çŸ©é˜µä¹˜æ³•é«˜æ•ˆè®¡ç®—

    results = []
    for i, text in enumerate(texts):
        sim_scores = similarities[i]

        # 3. è·å– top_k ç»“æœ
        if len(sim_scores) < top_k:
            top_k_indices = np.argsort(sim_scores)[::-1]  # å…¨éƒ¨å€’åº
        else:
            top_k_indices = np.argpartition(sim_scores, -top_k)[-top_k:]  # æœ€å¿«çš„topk
            top_k_indices = top_k_indices[np.argsort(sim_scores[top_k_indices])][::-1]  # topkå€’åº

        top_k_names = [str(name_list[j]) for j in top_k_indices]
        top_k_scores = [float(sim_scores[j]) for j in top_k_indices]

        # å°†ç»“æœç»„åˆæˆå­—å…¸
        result_dict = {
            "query": text,
            "match_tag": tag_list[i],
            "top_k_results": list(zip(top_k_names, top_k_scores))
        }
        results.append(result_dict)

    return results


def test_accuracy(batch_results):
    data_length = len(batch_results)
    top_n = [0, 0, 0, 0, 0]

    for result in batch_results:
        print(f"[{result['query']}] : [{result['match_tag']}]")

        for i, (name, score) in enumerate(result['top_k_results']):
            if result['match_tag'].lower().strip() == name.lower().strip():
                top_n[i] += 1
                if i == 0:
                    print(f"Top1 ğŸ’– : {name} [{score}]")
                else:
                    print(f"Top{i + 1} â¤ : {name} [{score}]")
                break

            print(f"--{name} [{score}]")
            if i == 4:
                print('âŒ')

        print()

    for i in range(1, len(top_n)):
        top_n[i] = top_n[i] + top_n[i - 1]

    for i in range(len(top_n)):
        print(f"Top {i + 1} accuracy: {top_n[i] / data_length * 100:.2f}%, {top_n[i]}/{data_length}")


def test_tag(tag, tag_vec_name):
    vec_data = np.load(f"../temp/{tag_vec_name}_vec.npy")
    name_list = np.load(f"../temp/{tag_vec_name}_vec_names.npy")
    print(f'åŠ è½½ {tag} å‘é‡åº“å’Œåç§°åº“')

    t1 = time.time()
    # æ‰¹é‡æœç´¢
    test_tag_list = test_data[tag]
    batch_results = batch_search_vec2text(ebay_text_list, test_tag_list, vec_data, name_list, model, top_k=5)

    print('time cost:', time.time() - t1)

    # æ‰“å°ç»“æœ
    test_accuracy(batch_results)
    print(f"----------- {tag} --------------")


if __name__ == '__main__':
    # åŠ è½½å¾®è°ƒåçš„æ¨¡å‹
    model = SentenceTransformer(r"D:\Code\ML\Model\huggingface\all-MiniLM-L6-v2_fine_tag5")

    test_data = pd.read_excel(r"D:\Code\ML\Text\embedding\ebay_2023_data01_test2.xlsx")
    ebay_text_list = test_data["ebay_text"]

    # test_tag("program", "program")
    test_tag("card_set", "cardSet")
    # test_tag("athlete", "athlete")
