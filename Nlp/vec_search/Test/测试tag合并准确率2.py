from sentence_transformers import SentenceTransformer
import numpy as np
import pandas as pd
import time
import itertools  # å¼•å…¥ itertools æ¨¡å—


# ä»ç¬¬ä¸€ä¸ªä»£ç ç‰‡æ®µå¤åˆ¶ combine_results å‡½æ•°
def combine_results(results_list, top_k_combined=5, weights=None):
    """
    ç»„åˆæ¥è‡ªå¤šä¸ªç´¢å¼•çš„æœç´¢ç»“æœï¼ˆåŠ æƒå¹³å‡ï¼‰ã€‚

    Args:
        results_list:  ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯æ¥è‡ªä¸€ä¸ªç´¢å¼•çš„æœç´¢ç»“æœåˆ—è¡¨ï¼ˆæ¯ä¸ªç»“æœæ˜¯ä¸€ä¸ªå­—å…¸ï¼‰ã€‚
        top_k_combined:  è¦è¿”å›çš„ç»„åˆç»“æœæ•°é‡ã€‚
        weights:  ä¸€ä¸ªå¯é€‰çš„æƒé‡åˆ—è¡¨ï¼Œç”¨äºåŠ æƒå¹³å‡ã€‚å¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨æ¯ä¸ªç´¢å¼•çš„æœ€é«˜åˆ†æ•°ä½œä¸ºæƒé‡ã€‚

    Returns:
        ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«ç»„åˆåçš„ç»“æœï¼ˆå­—å…¸ï¼‰ï¼ŒæŒ‰ç»„åˆåˆ†æ•°é™åºæ’åˆ—ã€‚
    """

    if weights is None:
        # ä½¿ç”¨æ¯ä¸ªç´¢å¼•çš„æœ€é«˜åˆ†æ•°ä½œä¸ºæƒé‡, é¿å…ç©ºåˆ—è¡¨
        weights = [results[0]['score'] if results else 1.0 for results in results_list]

    # æƒé‡å½’ä¸€
    sum_weight = sum(weights)
    normalized_weights = [w / sum_weight for w in weights]

    # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ç»„åˆ
    all_combinations = list(itertools.product(*results_list))

    combined_results = []
    for combination in all_combinations:
        combined_score = 0
        combined_names = []
        for i, result in enumerate(combination):
            combined_score += normalized_weights[i] * result['score']  # åŠ æƒå¹³å‡
            combined_names.append(result['name'])

        combined_results.append({
            "program": combined_names[0],  # ç»„åˆåç§°
            "card_set": combined_names[1],
            "athlete": combined_names[2],
            "combined_score": combined_score  # ç»„åˆåˆ†æ•°
        })

    # æŒ‰ç»„åˆåˆ†æ•°é™åºæ’åºï¼Œå¹¶è¿”å› top_k ä¸ªç»“æœ
    combined_results.sort(key=lambda x: x['combined_score'], reverse=True)
    return combined_results[:top_k_combined]


def batch_search_vec2text(texts, vec_data, name_list, model, top_k=5):  # ä¿®æ”¹: top_k é»˜è®¤å€¼ä¸º 10ï¼Œè¿”å› top_k ç»“æœ
    """
    æ‰¹é‡æœç´¢æ–‡æœ¬å¯¹åº”çš„å‘é‡ï¼Œå¹¶è¿”å›æœ€ç›¸ä¼¼çš„ top_k ä¸ªç»“æœã€‚
    (ä¿®æ”¹: top_k é»˜è®¤å€¼ä¸º 10, è¿”å› top_k ç»“æœ)

    Args:
        texts: å¾…æŸ¥è¯¢æ–‡æœ¬åˆ—è¡¨ã€‚
        vec_data: å‘é‡åº“æ•°æ®ã€‚
        name_list: å‘é‡åº“å¯¹åº”çš„åç§°åˆ—è¡¨ã€‚
        model: SentenceTransformer æ¨¡å‹ã€‚
        top_k: è¿”å›æœ€ç›¸ä¼¼ç»“æœçš„æ•°é‡ã€‚

    Returns:
        ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªç»“æœæ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« 'name' å’Œ 'score'ã€‚
    """

    # 1. æ‰¹é‡ç¼–ç æ–‡æœ¬
    output_vecs = model.encode(texts, normalize_embeddings=True, convert_to_numpy=True)

    # 2. æ‰¹é‡è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    similarities = np.dot(output_vecs, vec_data.T)

    # 3. è·å– top_k ç»“æœ (ä¿®æ”¹ï¼šè¿”å› top_k)
    top_k_indices = np.argsort(similarities, axis=1)[:, ::-1][:, :top_k]  # è·å– top_k ç´¢å¼•
    top_k_scores = np.take_along_axis(similarities, top_k_indices, axis=1)  # è·å– top_k åˆ†æ•°

    batch_results = []
    for i in range(len(texts)):
        results = []
        for j in range(top_k):
            results.append({'name': str(name_list[top_k_indices[i, j]]), 'score': top_k_scores[i, j]})
        batch_results.append(results)
    return batch_results  # è¿”å›ç»“æœåˆ—è¡¨


def test_combined_accuracy(model, test_data, top_k_per_index=10,
                           max_combinations=5):  # ä¿®æ”¹: æ·»åŠ  top_k_per_index å’Œ max_combinations å‚æ•°
    """
    æµ‹è¯•ç»„åˆå‡†ç¡®ç‡ï¼šè¾“å…¥ ebay æ–‡æœ¬ï¼Œè·å– top_k çš„ program, card_set, athlete çš„å‘é‡æœç´¢ç»“æœï¼Œ
    ç„¶åä½¿ç”¨ combine_results ç»„åˆç»“æœï¼Œå¹¶æµ‹è¯• top N (N=1 to max_combinations) çš„å‡†ç¡®ç‡ã€‚
    """
    ebay_text_list = test_data["ebay_text"].tolist()
    test_data_length = len(ebay_text_list)
    top_n_yes = [0] * max_combinations  # åˆå§‹åŒ– Top-N æ­£ç¡®è®¡æ•°åˆ—è¡¨

    # 1. åˆ†åˆ«è·å–ä¸‰ä¸ª tag çš„ top_k é¢„æµ‹ç»“æœ
    program_results = batch_search_vec2text(ebay_text_list, *load_vec_data("program"), model, top_k=top_k_per_index)
    card_set_results = batch_search_vec2text(ebay_text_list, *load_vec_data("cardSet"), model, top_k=top_k_per_index)
    athlete_results = batch_search_vec2text(ebay_text_list, *load_vec_data("athlete"), model, top_k=top_k_per_index)

    for i in range(test_data_length):
        # å‡†å¤‡å½“å‰æ ·æœ¬çš„æœç´¢ç»“æœåˆ—è¡¨ç»™ combine_results å‡½æ•°
        current_results_list = [
            program_results[i],
            card_set_results[i],
            athlete_results[i]
        ]

        # ç»„åˆç»“æœ
        combined_results = combine_results(current_results_list, top_k_combined=max_combinations)

        # æµ‹è¯•å‰nä¸ªçš„å‡†ç¡®æ•°é‡
        print(f"{test_data['ebay_text'].iloc[i]} "
              f"[{test_data["program"].iloc[i]}, {test_data["card_set"].iloc[i]}, {test_data["athlete"].iloc[i]}]")

        for j in range(max_combinations):
            this_combination = combined_results[j] if combined_results and len(
                combined_results) > j else None  # ç¡®ä¿ç´¢å¼•ä¸è¶Šç•Œ

            # æ£€æŸ¥é¢„æµ‹æ˜¯å¦æ­£ç¡®
            if this_combination and (
                    this_combination["program"].lower().strip() == test_data["program"].iloc[i].lower().strip() and
                    this_combination["card_set"].lower().strip() == test_data["card_set"].iloc[i].lower().strip() and
                    this_combination["athlete"].lower().strip() in test_data["athlete"].iloc[i].lower().strip()
            ):
                top_n_yes[j] += 1
                print(f"ğŸ’– Top {j + 1}: {this_combination}")
                break
            else:
                print(f"--{this_combination}")

            if j == max_combinations - 1:  # æœ€åä¸€ä¸ª top k ä¹Ÿæ²¡æ‰¾åˆ°
                print("âŒ")
        print()

    for i in range(1, max_combinations):
        top_n_yes[i] += top_n_yes[i - 1]

    for i in range(max_combinations):
        accuracy = top_n_yes[i] / test_data_length * 100
        print(f"Top {i + 1} Accuracy: {accuracy:.2f}% ({top_n_yes[i]}/{test_data_length})")
    return top_n_yes  # è¿”å› top_n_yes åˆ—è¡¨ï¼Œæ–¹ä¾¿è¿›ä¸€æ­¥åˆ†æ


def load_vec_data(tag_vec_name):
    """åŠ è½½å‘é‡æ•°æ®å’Œåç§°åˆ—è¡¨"""
    vec_data = np.load(f"../temp/{tag_vec_name}_vec.npy")
    name_list = np.load(f"../temp/{tag_vec_name}_vec_names.npy")
    print(f'åŠ è½½ {tag_vec_name} å‘é‡åº“å’Œåç§°åº“')
    return vec_data, name_list


if __name__ == '__main__':
    # åŠ è½½å¾®è°ƒåçš„æ¨¡å‹
    model = SentenceTransformer(r"D:\Code\ML\Model\huggingface\all-MiniLM-L6-v2_fine_tag7")
    # model = SentenceTransformer(r"D:\Code\ML\Model\huggingface\all-mpnet-base-v2_fine_tag01")

    test_data = pd.read_excel(r"D:\Code\ML\Text\embedding\ebay_2023_data01_test.xlsx")
    ebay_text_list = test_data["ebay_text"]

    # test_tag("program", "program")  # æ³¨é‡Šæ‰åŸæ¥çš„å•ä¸ª tag æµ‹è¯•
    # test_tag("card_set", "cardSet")
    # test_tag("athlete", "athlete")

    top_k_per_index = 5  # è®¾ç½®æ¯ä¸ªç´¢å¼•æœç´¢çš„ top_k å€¼
    max_combinations = 5  # è®¾ç½®ç»„åˆç»“æœæµ‹è¯•çš„ top_k å€¼ (Top-N ä¸­çš„ N)
    top_n_counts = test_combined_accuracy(model, test_data, top_k_per_index, max_combinations)  # è°ƒç”¨æ–°çš„ç»„åˆå‡†ç¡®ç‡æµ‹è¯•å‡½æ•°, å¹¶ä¼ é€’å‚æ•°

    print(f"Top N Counts: {top_n_counts}")  # æ‰“å° Top-N æ­£ç¡®æ•°é‡ï¼Œæ–¹ä¾¿è¿›ä¸€æ­¥åˆ†æ
