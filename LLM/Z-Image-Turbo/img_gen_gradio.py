import os
import sys

# =================ã€å…³é”®ä¿®å¤ã€‘=================
# 1. å¿…é¡»åœ¨ import torch ä¹‹å‰è®¾ç½®ï¼
# è¿™æ ·ç¨‹åºå¯åŠ¨æ—¶ï¼Œåªä¼šçœ‹åˆ°ä¸€å¼ æ˜¾å¡ï¼ˆå³ç‰©ç†ä¸Šçš„ GPU 2ï¼‰
os.environ["CUDA_VISIBLE_DEVICES"] = "2"
# ============================================

import torch
import gradio as gr
from diffusers import ZImagePipeline

MODEL_ID = "Tongyi-MAI/Z-Image-Turbo"

print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_ID}...")
print("æç¤ºï¼šå·²é…ç½®ä¸ºä»…ä½¿ç”¨ GPU 2 (Tesla V100)")

try:
    # åŠ è½½ç®¡é“
    pipe = ZImagePipeline.from_pretrained(
        MODEL_ID,
        torch_dtype=torch.bfloat16,
        use_safetensors=True,
    )

    # ================= æ˜¾å­˜ä¼˜åŒ– =================
    # 2. æ˜¾å¼å‘Šè¯‰ offload ä½¿ç”¨ "cuda:0"
    # (å› ä¸ºä¸Šé¢å±è”½äº†å…¶ä»–å¡ï¼Œæ‰€ä»¥è¿™é‡Œçš„ cuda:0 å®é™…ä¸Šå°±æ˜¯ç‰©ç† GPU 2)
    pipe.enable_model_cpu_offload(device="cuda:0")

    # å¼€å¯ VAE åˆ‡ç‰‡ (é˜²æ­¢è§£ç å¤§å›¾çˆ†æ˜¾å­˜)
    pipe.vae.enable_tiling()

    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼æ˜¾å¡é”å®šæ­£ç¡®ã€‚")

except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    exit()


# ================= ç”Ÿæˆå‡½æ•° =================
def generate_image(prompt, width, height, guidance_scale, steps, seed):
    if seed == -1:
        seed = torch.randint(0, 2147483647, (1,)).item()

    # è¿™é‡Œ generator æŒ‡å®š cuda å³å¯
    generator = torch.Generator(device="cuda").manual_seed(int(seed))

    print(f"ç”Ÿæˆä¸­... å°ºå¯¸: {width}x{height} | ç§å­: {seed}")

    try:
        image = pipe(
            prompt=prompt,
            width=int(width),
            height=int(height),
            guidance_scale=guidance_scale,
            num_inference_steps=steps,
            generator=generator
        ).images[0]
        return image, f"Used Seed: {seed} | Size: {width}x{height}"

    except RuntimeError as e:
        if "out of memory" in str(e):
            torch.cuda.empty_cache()
            return None, "âŒ æ˜¾å­˜ä¸è¶³ (OOM)ï¼è¯·å°è¯•å‡å°å°ºå¯¸ã€‚"
        else:
            return None, f"å‡ºé”™: {e}"


# ================= ç•Œé¢ =================
with gr.Blocks(title="Z-Image-Turbo") as demo:
    gr.Markdown("## ğŸš€ Z-Image-Turbo (GPU 2 ä¸“å±)")

    with gr.Row():
        with gr.Column():
            prompt_input = gr.Textbox(
                label="æç¤ºè¯",
                value="A majestic tiger sitting on a mountain peak, chinese painting style, 8k",
                lines=3
            )

            with gr.Row():
                width_slider = gr.Slider(256, 1280, value=768, step=64, label="å®½åº¦ (Width)")
                height_slider = gr.Slider(256, 1280, value=768, step=64, label="é«˜åº¦ (Height)")

            with gr.Row():
                steps_slider = gr.Slider(1, 20, value=8, step=1, label="æ­¥æ•°")
                guidance_slider = gr.Slider(0, 5, value=1.0, step=0.1, label="å¼•å¯¼ç³»æ•°")

            seed_input = gr.Number(value=-1, label="ç§å­ (-1 éšæœº)", precision=0)
            run_btn = gr.Button("ç”Ÿæˆ", variant="primary")

        with gr.Column():
            output_image = gr.Image(label="ç»“æœ", type="pil")
            status_output = gr.Textbox(label="çŠ¶æ€")

    run_btn.click(
        generate_image,
        [prompt_input, width_slider, height_slider, guidance_slider, steps_slider, seed_input],
        [output_image, status_output]
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)
    