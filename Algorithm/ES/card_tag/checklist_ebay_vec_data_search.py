import time
import itertools
from sentence_transformers import SentenceTransformer
import numpy as np
import pandas as pd
from elasticsearch import Elasticsearch, helpers
import os

os.environ.setdefault("DJANGO_SETTINGS_MODULE", "mysite.settings")

# Elasticsearch è¿æ¥é…ç½®
es_config = {
    "hosts": [{"host": "localhost", "port": 9200, "scheme": "http"},],
    "request_timeout": 30
    # å¦‚æœéœ€è¦ç”¨æˆ·åå’Œå¯†ç 
    # "http_auth": ("your_username", "your_password")
}

# åˆ›å»º Elasticsearch å®¢æˆ·ç«¯
es = Elasticsearch(**es_config)


# def vector_search(es_client, index_name, query_vector, top_k=5):
#     """æ‰§è¡Œå•ä¸ªå‘é‡æœç´¢ã€‚"""
#
#     search_query = {
#         "size": top_k,
#         "query": {
#             "knn": {  # ä½¿ç”¨kNN
#                 "field": "embedding",  # å…³é”®ä¿®æ”¹ï¼š ä½¿ç”¨ 'field' å‚æ•°æŒ‡å®šå­—æ®µå
#                 "query_vector": query_vector.tolist(),  # æŸ¥è¯¢å‘é‡
#                 "k": top_k,
#                 "num_candidates": 50  # å¢åŠ å€™é€‰é¡¹
#             }
#         }
#     }
#     response = es_client.search(index=index_name, body=search_query)
#     results = []
#     for hit in response['hits']['hits']:
#         results.append({
#             "name": hit['_source']['name'],
#             "score": hit['_score'],
#             # "text_id": hit["_source"]["text_id"] #å¯é€‰
#         })
#     return results

def vector_search_script_score(es_client, index_name, query_vector, top_k=5):
    """ä½¿ç”¨ script_score æŸ¥è¯¢æ‰§è¡Œå‘é‡æœç´¢ï¼ˆç‚¹ç§¯ï¼‰ã€‚"""

    search_query = {
        "size": top_k,
        "query": {
            "script_score": {
                "query": {"match_all": {}},
                "script": {
                    "source": "(dotProduct(params.query_vector, 'embedding') + 1) / 2",
                    "params": {
                        "query_vector": query_vector.tolist()
                    }
                }
            }
        }
    }
    response = es_client.search(index=index_name, body=search_query)
    results = []
    for hit in response['hits']['hits']:
        results.append({
            "name": hit['_source']['name'],
            "score": hit['_score'],
        })
    return results


def test_combined_accuracy(model, test_data, index_name, top_k_per_index):
    """
    æµ‹è¯•ç»„åˆå‡†ç¡®ç‡ï¼Œå¹¶é’ˆå¯¹ä¸åŒçš„ top_k_combined å€¼è¿›è¡Œæµ‹è¯•ã€‚
    """
    ebay_text_list = test_data["checklist_name"].tolist()
    test_data_length = len(ebay_text_list)
    query_vectors = model.encode(ebay_text_list, normalize_embeddings=True, convert_to_numpy=True)

    top_n_yes = [0] * top_k_per_index  # åˆå§‹åŒ– Top-N æ­£ç¡®è®¡æ•°åˆ—è¡¨

    for i, query_vector in enumerate(query_vectors):
        # ä»æ¯ä¸ªç´¢å¼•ä¸­æœç´¢
        single_search_results = vector_search_script_score(es, index_name, query_vector,
                                                           top_k=top_k_per_index)

        # æµ‹è¯•å‰nä¸ªçš„å‡†ç¡®æ•°é‡
        print(f"{test_data['checklist_name'].iloc[i]} "
              f"[{test_data["ebay_text"].iloc[i]}]")

        for j in range(5):
            this_combination = single_search_results[j] if single_search_results else None

            # æ£€æŸ¥é¢„æµ‹æ˜¯å¦æ­£ç¡®
            if this_combination and (
                    this_combination["name"].lower().strip() == test_data["ebay_text"].iloc[i].lower().strip()
            ):
                top_n_yes[j] += 1
                print(f"ğŸ’– Top {j + 1}: {this_combination}")
                break
            else:
                print(f"--{this_combination}")

            if j == 4:
                print("âŒ")
        print()

    for i in range(1, top_k_per_index):
        top_n_yes[i] += top_n_yes[i - 1]

    for i in range(top_k_per_index):
        accuracy = top_n_yes[i] / test_data_length * 100
        print(f"Top {i + 1} Accuracy: {accuracy:.2f}% ({top_n_yes[i]}/{test_data_length})")


def batch_vector_search_msearch(es_client, index_name, query_vectors, top_k=5):
    """ä½¿ç”¨ _msearch API æ‰§è¡Œæ‰¹é‡å‘é‡æœç´¢."""
    bulk_search_body = []
    for query_vector in query_vectors:
        search_header = {"index": index_name}
        search_query = {
            "size": top_k,
            "query": {
                "script_score": {
                    "query": {"match_all": {}},
                    "script": {
                        "source": "(dotProduct(params.query_vector, 'embedding') + 1) / 2",
                        "params": {
                            "query_vector": query_vector.tolist()
                        }
                    }
                }
            }
        }
        bulk_search_body.extend([search_header, search_query])

    responses = es_client.msearch(body=bulk_search_body)
    all_results = []
    for response in responses['responses']:  # éå†æ¯ä¸ªå­è¯·æ±‚çš„å“åº”
        results = []
        if 'hits' in response:  # æ£€æŸ¥æ˜¯å¦æœ‰ hits
            for hit in response['hits']['hits']:
                results.append({
                    "name": hit['_source']['name'],
                    "score": hit['_score'],
                })
        all_results.append(results)
    return all_results


def test_combined_accuracy_batch_chunked(model, test_data, index_name, top_k_per_index, batch_size=50):
    """
    ä½¿ç”¨æ‰¹é‡æœç´¢å’Œ Chunking æµ‹è¯•ç»„åˆå‡†ç¡®ç‡ï¼Œå¤„ç†å¤§å‹æ•°æ®é›†.
    """
    ebay_text_list = test_data["checklist_name"].tolist()
    test_data_length = len(ebay_text_list)
    query_vectors = model.encode(ebay_text_list, normalize_embeddings=True, convert_to_numpy=True)

    top_n_yes = [0] * top_k_per_index  # åˆå§‹åŒ– Top-N æ­£ç¡®è®¡æ•°åˆ—è¡¨
    total_processed = 0

    for i in range(0, test_data_length, batch_size):  # å¾ªç¯å¤„ç†æ•°æ®æ‰¹æ¬¡
        batch_ebay_texts = ebay_text_list[i:i + batch_size]
        batch_query_vectors = query_vectors[i:i + batch_size]

        # æ‰§è¡Œæ‰¹é‡æœç´¢ (é’ˆå¯¹å½“å‰æ‰¹æ¬¡çš„æ•°æ®)
        all_batch_results = batch_vector_search_msearch(es, index_name, batch_query_vectors, top_k=top_k_per_index)

        for j in range(len(batch_ebay_texts)):  # éå†å½“å‰æ‰¹æ¬¡çš„ç»“æœ
            single_batch_results = all_batch_results[j]
            query_index_in_full_data = i + j  # è®¡ç®—å½“å‰æŸ¥è¯¢åœ¨å®Œæ•´æ•°æ®é›†ä¸­çš„ç´¢å¼•

            # æµ‹è¯•å‰nä¸ªçš„å‡†ç¡®æ•°é‡
            print(f"{test_data['checklist_name'].iloc[query_index_in_full_data]} "
                  f"[{test_data["ebay_text"].iloc[query_index_in_full_data]}]")

            for k in range(5):
                this_combination = single_batch_results[k] if k < len(single_batch_results) else None

                # æ£€æŸ¥é¢„æµ‹æ˜¯å¦æ­£ç¡®
                if this_combination and (
                        this_combination["name"].lower().strip() == test_data["ebay_text"].iloc[
                    query_index_in_full_data].lower().strip()
                ):
                    top_n_yes[k] += 1
                    print(f"ğŸ’– Top {k + 1}: {this_combination}")
                    break
                else:
                    print(f"--{this_combination}")

                if k == 4:
                    print("âŒ")
            print()
            total_processed += 1

    for i in range(1, top_k_per_index):
        top_n_yes[i] += top_n_yes[i - 1]

    for i in range(top_k_per_index):
        accuracy = top_n_yes[i] / test_data_length * 100
        print(f"Top {i + 1} Accuracy: {accuracy:.2f}% ({top_n_yes[i]}/{test_data_length})")
    print(f"Total processed: {total_processed}")  # éªŒè¯å¤„ç†äº†æ‰€æœ‰æ•°æ®


if __name__ == '__main__':
    # SentenceTransformer æ¨¡å‹è·¯å¾„
    model_path = r'D:\Code\ML\Model\huggingface\all-MiniLM-L6-v2_checklist_ebay03'  # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹è·¯å¾„
    model = SentenceTransformer(model_path)

    index_name_list = 'checklist_ebay_vec_data_2023'
    top_k_per_index = 5  # æ¯ä¸ªç´¢å¼•è¿”å›çš„å‰ k ä¸ªç»“æœ

    test_data = pd.read_excel(r"D:\Code\ML\Text\embedding\checklist_ebay_data_2023\checklist_ebay_data_test.xlsx")
    # test_combined_accuracy(model, test_data, index_name_list, top_k_per_index)
    test_combined_accuracy_batch_chunked(model, test_data, index_name_list, top_k_per_index)

    # æµ‹è¯•å•ä¸ªæ¡ˆä¾‹
    # ebay_text = "2023-24 Panini Mosaic #6 Stephen Curry Elevate Mosaic Green Warriors"
    # query_vector = model.encode(ebay_text, normalize_embeddings=True, convert_to_numpy=True)
    # all_results = []
    # for index_name in index_name_list:
    #     single_search_results = vector_search_script_score(es, index_name, query_vector,
    #                                                        top_k=top_k_per_index)
    #     all_results.append(single_search_results)
    # combined_results = combine_results(all_results, top_k_combined=5)
    #
    # print(combined_results)
    # print()


'''
Top 1 Accuracy: 54.41% (6843/12577)
Top 2 Accuracy: 73.64% (9262/12577)
Top 3 Accuracy: 82.69% (10400/12577)
Top 4 Accuracy: 86.90% (10929/12577)
Top 5 Accuracy: 89.50% (11257/12577)
Total processed: 12577
'''
